## 进程与线程

进程是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。

进程有三个特征：
1、独立性：进程是系统中独立存在的实体，他可以拥有自己独立的资源，每个进程都拥有自己私有的地址空间。
2、动态性：进程与程序的区别在于，程序只是一个静态的集合，而进程是一个正在系统中活动的指令集合。
3、并发性：多个进程可以在单个处理器上并发执行，多个进程之间不会相互影响。
线程也被称为轻量级进程，线程是进程的单元。操作系统可以同时执行多个任务，每个任务就是进程，进程可以同时执行多个任务，每个任务就是线程。

做个简单的比喻：进程=火车，线程=车厢

- 线程在进程下行进（单纯的车厢无法运行）
- 一个进程可以包含多个线程（一辆火车可以有多个车厢）
- 不同进程间数据很难共享（一辆火车上的乘客很难换到另外一辆火车，比如站点换乘）
- 同一进程下不同线程间数据很易共享（A车厢换到B车厢很容易）
- 进程要比线程消耗更多的计算机资源（采用多列火车相比多个车厢更耗资源）
- 进程间不会相互影响，一个线程挂掉将导致整个进程挂掉（一列火车不会影响到另外一列火车，但是如果一列火车上中间的一节车厢着火了，将影响到所有车厢）
- 进程可以拓展到多机，进程最多适合多核（不同火车可以开在多个轨道上，同一火车的车厢不能在行进的不同的轨道上）
- 进程使用的内存地址可以上锁，即一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。（比如火车上的洗手间）－"互斥锁"
- 进程使用的内存地址可以限定使用量（比如火车上的餐厅，最多只允许多少人进入，如果满了需要在门口等，等有人出来了才能进去）－“信号量”

### 进程

进程（Process）是计算机中的程序关于某数据集合上的一次运行活动，是**系统进行资源分配和调度的基本单位**，是[操作系统](http://baike.baidu.com/view/880.htm)结构的基础。在早期面向进程设计的计算机结构中，进程是程序的基本执行实体；在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。

　　进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。它可以申请和拥有系统资源，是一个动态的概念，是一个活动的实体。它不只是程序的[代码](http://baike.baidu.com/view/41.htm)，还包括当前的活动，通过[程序计数器](http://baike.baidu.com/view/178145.htm)的值和处理[寄存器](http://baike.baidu.com/view/6159.htm)的内容来表示。

　　进程的概念主要有两点：第一，进程是一个实体。**每一个进程都有它自己的地址空间**，一般情况下，包括[文本](http://baike.baidu.com/view/300107.htm)区域（text region）、数据区域（data region）和[堆栈](http://baike.baidu.com/view/93201.htm)（stack region）。文本区域存储处理器执行的代码；数据区域存储变量和进程执行期间使用的动态分配的内存；堆栈区域存储着活动过程调用的指令和本地变量。第二，进程是一个“执行中的程序”。程序是一个没有生命的实体，只有[处理](http://baike.baidu.com/view/989420.htm)器赋予程序生命时（操作系统执行之），它才能成为一个活动的实体，我们称其为[进程](http://baike.baidu.com/view/19746.htm)。

进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。**由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。**

### 线程

**线程是进程的一个实体,是CPU调度和分派的基本单位**,它是比进程更小的能独立运行的基本单位.**线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)**,但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。

一个线程可以创建和撤消另一个线程，同一进程中的多个线程之间可以并发执行。由于线程之间的相互制约，致使线程 在运行中呈现出间断性。线程也有[就绪](http://baike.baidu.com/view/654230.htm)、[阻塞](http://baike.baidu.com/view/497285.htm)和[运行](http://baike.baidu.com/view/1026025.htm)三种基本状态。就绪状态是指线程具备运行的所有条件，逻辑上可以运行，在等待处理机；运行状态是指线程占有处理机正在运行；阻塞状态是指线程在等待一个事件（如某个信号量），逻辑上不可执行。每一个程序都至少有一个线程，若程序只有一个线程，那就是程序本身。

线程是程序中一个单一的顺序控制流程。进程内一个相对独立的、可调度的执行单元，是系统独立调度和分派CPU的基本单位指[运行](http://baike.baidu.com/view/1026025.htm)中的程序的调度单位。在单个程序中同时运行多个线程完成不同的工作，称为[多线程](http://baike.baidu.com/view/65706.htm)。

### 协程

**协程是一种用户态的轻量级线程，**协程的调度完全由**用户控制**。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

### 进程、线程、协程的区别

#### 概念

对于进程来说，子进程是父进程的复制品，从父进程那里获得父进程的数据空间，堆和栈的复制品。

而线程，相对于进程而言，是一个更加接近于执行体的概念，可以和同进程的其他线程之间直接共享数据，而且拥有自己的栈空间，拥有独立序列。

#### 进程、线程共同点

它们都能提高程序的并发度，提高程序运行效率和响应时间。线程和进程在使用上各有优缺点。 线程执行开销比较小，但不利于资源的管理和保护，而进程相反。同时，线程适合在SMP机器上运行，而进程可以跨机器迁移。

#### 进程、线程不同点

多进程中每个进程有自己的地址空间，线程则共享地址空间。

所有其他区别都是因为这个区别产生的。比如说：

1) 地址空间:线程是进程内的一个执行单元，进程内至少有一个线程，它们共享进程的地址空间，而进程有自己独立的地址空间
2) 资源拥有:进程是资源分配和拥有的单位,同一个进程内的线程共享进程的资源
3) 线程是处理器调度的基本单位,但进程不是
4) 二者均可并发执行
5) 每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口，但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制
   1) 速度。线程产生的速度快，通讯快，切换快，因为他们处于同一地址空间。 
   2) 线程的资源利用率好。 
   3) 线程使用公共变量或者内存的时候需要同步机制，但进程不用。

而他们通信方式的差异也仍然是由于这个根本原因造成的。

#### 线程、协程比较

1) 一个线程可以多个协程，一个进程也可以单独拥有多个协程，这样python中则能使用多核CPU。

2) 线程进程都是同步机制，而协程则是异步

3) 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态

### 通信方式之间的差异

因为那个根本原因，实际上只有进程间需要通信,同一进程的线程共享地址空间,没有通信的必要，但要做好同步/互斥,保护共享的全局变量。

而进程间通信无论是信号，管道pipe还是共享内存都是由操作系统保证的，是系统调用。

### 进程通信

#### 管道(pipe)

管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

#### 有名管道 (namedpipe)

有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。

#### 信号量(semaphore)

信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

#### 消息队列(messagequeue)

消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

#### 信号 (sinal)

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

#### 共享内存(shared memory)

共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。

#### 套接字(socket)

套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同设备及其间的进程通信。

### 线程间的通信方式

#### 锁机制：包括互斥锁、条件变量、读写锁

互斥锁提供了以排他方式防止数据结构被并发修改的方法。 
读写锁允许多个线程同时读共享数据，而对写操作是互斥的。 
条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。

wait/notify 等待

Volatile 内存共享

CountDownLatch 并发工具

CyclicBarrier 并发工具

#### 信号量机制(Semaphore)

包括无名线程信号量和命名线程信号量。

#### 信号机制(Signal)

类似进程间的信号处理。

线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。

### 浏览器的进程与线程

#### 多进程浏览器

![img](https://img2018.cnblogs.com/blog/998371/201906/998371-20190629174001820-1466393552.png)
chrome浏览器使用的是多进程多线程模式，因为现在的网页复杂性非常高。如果整个浏览器是单进程的，有可能某个page界面的抛错就会导致整个浏览器的crash。同时多个界面互相可以访问相同的内存和相同的执行环境，安全性也是一个大的问题，所以浏览器需要采用多进程模式。

浏览器的进程大概分为以下这几种：

- 1，浏览器主进程(Browser进程)：控制chrome的地址栏，书签栏，返回和前进按钮，同时还有浏览器的不可见部分，例如网络请求和文件访问
- 2，第三方插件进程：每种插件一个进程，插件运行时才会创建
- 3，浏览器渲染进程（浏览器内核，内部是多线程的）：负责界面渲染，脚本执行，事件处理等
- 4，GPU进程：最多一个，用于3D绘制
  ![img](https://img2018.cnblogs.com/blog/998371/201906/998371-20190629174055243-1647511949.png)

同时，浏览器中的每一个frame框也都是一个独立的进程，因为浏览器的安全策略中，来自不同源的界面，在没有授权前不可以访问另一个界面的数据。同时给不同源的界面分配不同的进程可以有效的实现这一效果。

#### 浏览器内核

浏览器内核是通过取得页面内容，整理信息，计算和组合最终输出可视化的图像结果，通常也被视为浏览器渲染进程。Chrome浏览器为每个Tab页面单独启用进程，因此每个tab网页都有其独立的渲染引擎实例。有些渲染进程会被浏览器自己的优化机制进行合并。

#### 浏览器内核是多线程的

![img](https://img2018.cnblogs.com/blog/998371/201906/998371-20190629174208092-1202769259.png)

- GUI线程

> 负责渲染浏览器界面，GUI更新会被保存在一个队列中等到JS引擎空闲时立即被执行，当界面需要重绘或由于某种操作引发的reflow时，该线程就会执行。

- js引擎线程

> 也称为JS内核，负责处理JavaScript脚本程序，JS引擎一直等待着任务队列中任务的到来，然后加以处理，一个Tab页中无论什么时候都只有一个JS线程在运行JS程序

- 定时触发器线程 （多个定时器时是否会有多个定时触发线程）

> 传说中的setInterval与setTimeout所在线程, 计数线程，浏览器定时计数器并不是由JS引擎计数的。

- 事件触发线程

> 属于浏览器而不是JS引擎，当JS引擎执行代码块如setTimeOut时（也可来自浏览器内核的其他线程,如鼠标点击、AJAX异步请求等），会将对应任务添加到事件线程中。当对应的事件符合触发条件被触发时，该线程会把是事件添加到待处理队列的队尾，等待JS引擎的处理。

- 异步http请求线程

> XMLHttpRequest在连接后是通过浏览器新开的一个线程请求。当检测到状态更新时，如果没有设置回调函数，异步线程就产生状态 变更事件，将这个回调再放入事件队列中，等待JS引擎执行。

由于JavaScript是可操纵DOM的，如果在修改这些元素属性同时渲染界面（即JavaScript线程和UI线程同时运行），那么渲染线程前后获得的元素数据就可能不一致了。因此为了防止渲染出现不可预期的结果，浏览器设置GUI渲染线程与JavaScript引擎为互斥的关系，当JavaScript引擎执行时GUI线程会被挂起，GUI更新会被保存在一个队列中等到引擎线程空闲时立即被执行。

浏览器内核的主要目标是将html+css+js渲染成开发者预期的UI,

#### Browser进程和浏览器内核通信过程

经过上边的各个概念的讲解，我们已经对浏览器是多进程多线程的概念有了大致的认知，下边我们看下浏览器的架构多进程的互相协作，首先引用一张架构图
![img](https://img2018.cnblogs.com/blog/998371/201906/998371-20190629174417674-766124453.png)
每个渲染进程都有一个全局renderprocess对象来管理和主进程的通信并维护全局状态。浏览器为每一个渲染进程都维护一个相应的RenderProcessHost,来管理主进程和渲染进程之间的状态以及沟通。主进程和渲染进程的通讯使用的是 Chromium的 IPC 系统。

每个渲染进程中，都有一个或多个renderview对象，由RenderProcess来管理，对应于每个tab页中的内容。RenderProcess负责tab页中所有发生的事情，其中主线程处理我们发送给用户的大部分代码，当然也会有web worker或者service worker处理一部分js代码。大概的模式可看我们之前介绍的浏览器内核。

## 进程调度策略

**1. 先来先服务 （FCFS）**

在所有调度算法中，最简单的是非抢占式的FCFS算法。既可用于作业调度，也可用于进程调度。每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。

**优点**：易于理解且实现简单，只需要一个队列(FIFO)，且相当公平

**缺点**：比较有利于长进程，而不利于短进程，有利于CPU 繁忙的进程，而不利于I/O 繁忙的进程

**2. 最短作业优先（SJF）/短进程优先(SPN)**

对预计执行时间短的进程优先分派处理机。通常后来的短进程不抢先正在执行的进程。

**优点**：相比FCFS 算法，该算法可改善平均周转时间和平均带权周转时间，缩短进程的等待时间，提高系统的吞吐量。

**缺点**：对长进程非常不利，可能长时间得不到执行，且未能依据进程的紧迫程度来划分执行的优先级，以及难以准确估计进程的执行时间，从而影响调度性能。

**3. 最高响应比优先法(HRRN)**

最高响应比优先法(HRRN)是对FCFS方式和SJF方式的一种综合平衡。***\**FCFS方式只考虑每个作业的等待时间而未考虑执行时间的长短，而SJF方式只考虑执行时间而未考虑等待时间的长短。\**\***HRRN调度策略同时考虑每个作业的等待时间长短和估计需要的执行时间长短，从中选出响应比最高的作业投入执行。这样，即使是长作业，随着它等待时间的增加，W / T也就随着增加，也就有机会获得调度执行。这种算法是介于FCFS和SJF之间的一种折中算法。

**响应比R定义如下： R =(W+T)/T = 1+W/T**

其中T为该作业估计需要的执行时间，W为作业在后备状态队列中的等待时间。每当要进行作业调度时，系统计算每个作业的响应比，选择其中R最大者投入执行。

**优点**：由于长作业也有机会投入运行，在同一时间内处理的作业数显然要少于SJF法，从而采用HRRN方式时其吞吐量将小于采用SJF 法时的吞吐量。

**缺点**：由于每次调度前要计算响应比，系统开销也要相应增加。

**4. 时间片轮转算法（RR，Round-Robin）**

该算法采用剥夺策略。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。

**算法原理**：让就绪进程以FCFS 的方式按时间片轮流使用CPU 的调度方式，即将系统中所有的就绪进程按照FCFS 原则，排成一个队列，每次调度时将CPU 分派给队首进程，让其执行一个时间片，时间片的长度从几个ms 到几百ms。在一个时间片结束时，发生时钟中断，调度程序据此暂停当前进程的执行，将其送到就绪队列的末尾，并通过上下文切换执行当前的队首进程，进程可以未使用完一个时间片，就出让CPU（如阻塞）。

**优点**：时间片轮转调度算法的特点是简单易行、平均响应时间短。

**缺点**：不利于处理紧急作业。在时间片轮转算法中，时间片的大小对系统性能的影响很大，因此时间片的大小应选择恰当怎样确定时间片的大小：

**时间片大小的确定**

1.系统对响应时间的要求

2.就绪队列中进程的数目

3.系统的处理能力

**5.多级反馈队列(Multilevel Feedback Queue)**

多级反馈队列调度算法是一种CPU处理机调度算法，UNIX操作系统采取的便是这种调度算法。

**调度算法描述：**

1、进程在进入待调度的队列等待时，首先进入优先级最高的Q1等待。

2、首先调度优先级高的队列中的进程。若高优先级中队列中已没有调度的进程，则调度次优先级队列中的进程。例如：Q1,Q2,Q3三个队列，只有在Q1中没有进程等待时才去调度Q2，同理，只有Q1,Q2都为空时才会去调度Q3。

3、对于同一个队列中的各个进程，按照时间片轮转法调度。比如Q1队列的时间片为N，那么Q1中的作业在经历了N个时间片后若还没有完成，则进入Q2队列等待，若Q2的时间片用完后作业还不能完成，一直进入下一级队列，直至完成。

4、在低优先级的队列中的进程在运行时，又有新到达的作业，那么在运行完这个时间片后，CPU马上分配给新到达的作业（抢占式）。

## [多线程的三个特性：原子性、可见性、有序性](https://www.cnblogs.com/java-spring/p/8316964.html)

原子性：是指一个操作是不可中断的。即使是多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。比如，对于一个静态全局变量int i，两个线程同时对它赋值，线程A给他赋值为1，线程B给他赋值为-1。那么不管这两个线程。以何种方式。何种步调工作，i的值要么是1，要么是-1.线程A和线程B之间是没有干扰的。这就是原子性的一个特点，不可被中断。

可见性：是指当一个线程修改了某一个共享变量的值，其他线程是否能够立即知道这个修改。显然，对于串行来说，可见性问题是不存在的。

有序性：在并发时，程序的执行可能会出现乱序。给人的直观感觉就是：写在前面的代码，会在后面执行。有序性问题的原因是因为程序在。执行时，可能会进行指令重排，重排后的指令与原指令的顺序未必一致。

## 进程切换

进行进程切换就是从正在运行的进程中收回处理器，然后再使待运行进程来占用处理器。 这里所说的从某个进程收回处理器，实质上就是把进程存放在处理器的寄存器中的中间数据找个地方存起来，从而把处理器的寄存器腾出来让其他进程使用。那么被中止运行进程的中间数据存在何处好呢？当然这个地方应该是进程的私有[堆栈](https://baike.baidu.com/item/堆栈/1682032)。

进程上下文切换由以下4个步骤组成:

1)决定是否作[上下文切换](https://baike.baidu.com/item/上下文切换)以及是否允许作上下文切换。包括对[进程调度](https://baike.baidu.com/item/进程调度)原因的检查分析，以及当前执行进程的资格和CPU执行方式的检查等。在操作系统中，[上下文切换](https://baike.baidu.com/item/上下文切换)程序并不是每时每刻都在检查和分析是否可作上下文切换，它们设置有适当的时机。

(2)保存当前执行进程的上下文。这里所说的当前执行进程，实际上是指调用[上下文切换](https://baike.baidu.com/item/上下文切换)程序之前的执行进程。如果[上下文切换](https://baike.baidu.com/item/上下文切换)不是被那个当前执行进程所调用，且不属于该进程，则所保存的上下文应是先前执行进程的上下文，或称为“老”[进程上下文](https://baike.baidu.com/item/进程上下文)。显然，[上下文切换](https://baike.baidu.com/item/上下文切换)程序不能破坏“老”进程的上下文结构。

(3)使用[进程调度](https://baike.baidu.com/item/进程调度)算法，选择一处于就绪状态的进程。

(4)恢复或装配所选进程的上下文，将CPU控制权交到所选进程手中。

## 单核cpu为什么要用多线程？

有频繁的IO操作时使用多线程会大大提高程序的执行效率。

## 程序在cpu中执行过程?

当程序要执行的部分被装载到内存后，CPU要从内存中取出指令，然后指令解码(以便知道类型和操作数，简单的理解为CPU要知道这是什么指令)，然后执行该指令。再然后取下一个指令、解码、执行，以此类推直到程序退出。

## 程序执行的原理, 当 CPU 执行程序, 读取变量时, 变量存储在内存, 三级缓存和寄存器中有哪些区别？

  **1. 寄存器**是中央处理器内的组成部份。寄存器是有限存贮容量的高速存贮部件，它们可用来暂存指令、数据和位址。在中央处理器的**控制部件**中，包含的寄存器有**指令寄存器(IR)**和**程序计数器(PC)。**在中央处理器的**算术及逻辑部件**中，包含的寄存器有**累加器(ACC)。

2. 内存包含的范围非常广，一般分为只读存储器（ROM）、随机存储器（RAM）和高速缓存存储器（cache）。

3. 寄存器是CPU内部的元件，寄存器拥有非常高的读写速度，所以在寄存器之间的数据传送非常快。
4. **Cache** ：**即高速缓冲存储器**，**是位于CPU与主内存间的一种容量较小但速度很高的存储器**。由于CPU的速度远高于主内存，CPU直接从内存中存取数据要等待一定时间周期，**Cache中保存着CPU刚用过或循环使用的一部分数据**，当CPU再次使用该部分数据时可从Cache中直接调用,这样就减少了CPU的等待时间,提高了系统的效率。**Cache又分为一级Cache(L1 Cache)和二级Cache(L2 Cache)，L1 Cache集成在CPU内部**，L2 Cache早期一般是焊在主板上,**现在也都集成在CPU内部**，常见的容量有256KB或512KB L2 Cache。

总结：**大致来说数据是通过内存-Cache-寄存器，Cache缓存则是为了弥补CPU与内存之间运算速度的差异而设置的的部件。**

寄存器是CPU的内部组成单元,是CPU运算时取指令和数据的地方，速度很快，寄存器可以用来暂存指令、数据和地址。在CPU中，通常有通用寄存器，如指令寄存器IR；特殊功能寄存器，如程序计数器PC、sp等。

Cache：缓存即就是用于暂时存放内存中的数据，若果寄存器要取内存中的一部分数据时，可直接从缓存中取到，这样可以调高速度。高速缓存是内存的部分拷贝。

CPU <--- > 寄存器<--- > 缓存<--- >内存

寄存器的工作方式很简单，只有两步：（1）找到相关的位，（2）读取这些位。

内存的工作方式就要复杂得多：

（1）找到数据的指针。（指针可能存放在寄存器内，所以这一步就已经包括寄存器的全部工作了。）

（2）将指针送往内存管理单元（MMU），由MMU将虚拟的内存地址翻译成实际的物理地址。

（3）将物理地址送往内存控制器（memory controller），由内存控制器找出该地址在哪一根内存插槽（bank）上。

（4）确定数据在哪一个内存块（chunk）上，从该块读取数据。

（5）数据先送回内存控制器，再送回CPU，然后开始使用。

内存的工作流程比寄存器多出许多步。每一步都会产生延迟，累积起来就使得内存比寄存器慢得多。

为了缓解寄存器与内存之间的巨大速度差异，硬件设计师做出了许多努力，包括在CPU内部设置缓存、优化CPU工作方式，尽量一次性从内存读取指令所要用到的全部数据等等。

## 如果某个线程挂掉了，这个进程会挂掉吗？

理论上讲，线程挂掉只是触发了 segment fault ，该信号在系统中默认的处理方式是终结该线程所在的进程，如果对该信号进行屏蔽也是可以的。

但是，重点来了，触发 segment fault 的位置如果是 stack，那么只要进程屏蔽了该信号，那么对其他的线程是没有影响；如果触发 segment fault 的位置如果是 heap、全局变量等线程共享的部分，那么就算屏蔽了该信号，那么其他线程也会出现问题，只是时间上的事情。

总结来说，

如果进程不屏蔽 segment fault 信号，一个线程崩溃，所有线程终结。
如果屏蔽 segment fault 信号，且线程崩溃的位置是线程私有位置（stack），那么其他线程没有问题。
如果屏蔽 segment fault 信号，且线程崩溃的位置是线程共享位置（heap、全局变量等），那么其他线程也会出现问题。

## 多线程同步

### **一、同步概念**

　　为什么要特意说一下同步概念呢？因为它跟其他领域的“同步”有些差异。

　　所谓同步，即同时起步，协调一致。不同的对象，对“同步”的理解方式略有不同。如，设备同步，是指在两个设备之间规定一个共同的时间参考；数据库同步，是指让两个或多个数据库内容保持一致，或者按需要部分保持一致；文件同步，是指让两个或多个文件夹里的文件保持一致，等等。而，编程中、通信中所说的同步与生活中大家印象中的同步概念略有差异。“同”字应是指协同、协助、互相配合。主旨在协同步调，按预定的先后次序运行。

### **二、线程同步方式**

　　这篇博客主要介绍四种方式，方式通用标识互斥锁（互斥量）pthread_mutex_读写锁 pthread_rwlock_条件变量pthread_cond_信号量sem_

　　 表中的“通用标识”，指的是那种同步方式的函数、类型都那么开头的，方便记忆；还有其他方式，自旋锁、屏蔽，感觉不常用，有兴趣可以阅读APUE。

###  **三、互斥锁（互斥量）**

![img](https://pic2.zhimg.com/80/v2-c679f9bc0efa0b92efc42fc6a73604d5_1440w.jpg)

Linux中提供一把互斥锁mutex（也称之为互斥量）。

　　每个线程在对资源操作前都尝试先加锁，成功加锁才能操作，操作结束解锁。

资源还是共享的，线程间也还是竞争的，

但通过“锁”就将资源的访问变成互斥操作，而后与时间有关的错误也不会再产生了。

### **四、读写锁**

#### 特性

（1）读写锁是“写模式加锁”时， 解锁前，所有对该锁加锁的线程都会被阻塞。

（2）读写锁是“读模式加锁”时， 如果线程以读模式对其加锁会成功；如果线程以写模式加锁会阻塞。

（3）读写锁是“读模式加锁”时， 既有试图以写模式加锁的线程，也有试图以读模式加锁的线程。那么读写锁会阻塞随后的读模式锁请求。优先满足写模式锁。**读锁、写锁并行阻塞，写锁优先级高**

读写锁也叫共享-独占锁。当读写锁以读模式锁住时，它是以共享模式锁住的；当它以写模式锁住时，它是以独占模式锁住的。**写独占、读共享。**

读写锁非常适合于对数据结构读的次数远大于写的情况。

写独占、读共享；写锁优先级高。

### 五、条件变量

条件变量（condition）：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。 

互斥量是防止多线程同时访问共享的互斥变量来保护临界区。

条件变量是多线程间可以通过它来告知其他线程某个状态发生了改变，让等待在这个条件变量的线程继续执行。

设置一个条件变量让线程1等待在一个临界区的前面，当其他线程给这个变量执行通知操作时，线程1才会被唤醒，继续向下执行。

条件变量总是和互斥量一起使用，互斥量保护着条件变量，防止多个线程对条件变量产生竞争。

### 六、信号量Semaphore

简单的说，信号量内核对象，也是[多线程](https://so.csdn.net/so/search?q=多线程&spm=1001.2101.3001.7020)同步的一种机制，它可以对资源访问进行计数，包括最大资源计数和当前资源计数，是两个32位的值；另外，计数是以原子访问的方式进行，由操作系统维护；

- 最大资源计数，表示可以控件的最大资源数量
- 当前资源计数，表示当前可用资源的数量

信号量的规则：

- 如果当前资源计数器大于0，那么信号量处于触发状态
- 如果当前资源计数器等于0，那么信号量处于未触发状态
- 系统绝对不会让当前资源计数器变为负数
- 当前资源计数器决定不会大于最大资源计数

信号量机制：

以一个停车场的运作为例。假设停车场只有三个车位，一开始三个车位都是空的。这时如果同时来了五辆车，看门人允许其中三辆直接进入，然后放下车拦，剩下的车则必须在入口等待，此后来的车也都不得不在入口处等待。这时，有一辆车离开停车场，看门人得知后，打开车拦，放入外面的一辆进去，如果又离开两辆，则又可以放入两辆，如此往复。

在这个停车场系统中，车位是公共资源，每辆车好比一个线程，看门人起的就是信号量的作用，当当前资源计数大于0，信号量处于触发状态，线程编程可调度；

## 编码方式

常见的一些字符编码方式无非有：Unicode、ASCII、GBK、GB2312、UTF-8。下面先对常见的这一些字符编码方式作下说明：

**1.ASCII码**

这是美国在19世纪60年代的时候为了建立英文字符和二进制的关系时制定的编码规范，它能表示128个字符，其中包括英文字符、阿拉伯数字、西文字符以及32个控制字符。它用一个字节来表示具体的字符，但它只用后7位来表示字符（2^7=128），最前面的一位统一规定为0。

**2.扩展的ASCII码**

原本的ASCII码对于英文语言的国家是够用了，但是欧洲国家的一些语言会有拼音，这时7个字节就不够用了。因此一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使 用的编码体系，可以表示最多256个符号。但这时问题也出现了：**不同的国家有不同的字母，因此，哪怕它们都使用256个符号的编码方式，代表的字母却不一样。**比如，130在法语编码 中代表了é，在希伯来语编码中却代表了字母Gimel (ג)，在俄语编码中又会代表另一个符号。但是不管怎样，所有这些编码方式中，0—127表示的符号是一样的，不一样的只是128—255的这一段。这个问题就直接促使了Unicode编码的产生。

**3.Unicode符号集**

正如上一节所说，世界上存在着多种编码方式，同一个二进制数字可以被解释成不同的符号。因此，要想打开一个文本文件，就必须知道它的编码方式，否则用错误的编码方式解读，就会出现乱码。为什么电子邮件常常出现乱码？就是因为发信人和收信人使用的编码方式不一样。而Unicode就是这样一种编码：它包含了世界上所有的符号，并且每一个符号都是独一无二的。比如，U+0639表示阿拉伯字母Ain，U+0041表示英语的大写字母A，U+4E25表示汉字“严”。具体的符号对应表，可以查询[unicode.org](https://link.zhihu.com/?target=https%3A//blog.csdn.net/csywwx2008/article/details/unicode.org)，或者专门的[汉字对应表 ](https://link.zhihu.com/?target=http%3A//www.chi2ko.com/tool/CJK.htm)。很多人都说Unicode编码，但其实Unicode是一个符号集（世界上所有符号的符号集），而不是一种新的编码方式。

但是正因为Unicode包含了所有的字符，而有些国家的字符用一个字节便可以表示，而有些国家的字符要用多个字节才能表示出来。即产生了两个问题：第一，如果有两个字节的数据，那计算机怎么知道这两个字节是表示一个汉字呢？还是表示两个英文字母呢？第二，因为不同字符需要的存储长度不一样，那么如果Unicode规定用2个字节存储字符，那么英文字符存储时前面1个字节都是0，这就大大浪费了存储空间。

上面两个问题造成的结果是：1）出现了unicode的多种存储方式，也就是说有许多种不同的二进制格式，可以用来表示unicode。2）unicode在很长一段时间内无法推广，直到互联网的出现。

**4.UTF-8**

互联网的普及，强烈要求出现一种统一的编码方式。UTF-8就是在互联网上使用最广的一种unicode的实现方式。其他实现方式还包括UTF-16和UTF-32，不过在互联网上基本不用。**重复一遍，这里的关系是，UTF-8是Unicode的实现方式之一。**

UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。

UTF-8的编码规则很简单，只有两条：

1）对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的。

2）对于n字节的符号（n>1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码。

**5.GBK/GB2312/GB18030**

GBK和GB2312都是针对简体字的编码，只是GB2312只支持六千多个汉字的编码，而GBK支持1万多个汉字编码。而GB18030是用于繁体字的编码。汉字存储时都使用两个字节来储存。

**总的来说：**

**ASCII编码：**用来表示英文，它使用1个字节表示，其中第一位规定为0，其他7位存储数据，一共可以表示128个字符。

**拓展ASCII编码：**用于表示更多的欧洲文字，用8个位存储数据，一共可以表示256个字符

**GBK/GB2312/GB18030：**表示汉字。GBK/GB2312表示简体中文，GB18030表示繁体中文。

**Unicode编码：**包含世界上所有的字符，是一个字符集。

**UTF-8：**是Unicode字符的实现方式之一，它使用1-4个字符表示一个符号，根据不同的符号而变化字节长度。

## js为什么要设计成单线程？

这主要和js的用途有关，js是作为浏览器的脚本语言，主要是实现用户与浏览器的交互，以及操作dom；这决定了它只能是单线程，否则会带来很复杂的同步问题。 举个例子：如果js被设计了多线程，如果有一个线程要修改一个dom元素，另一个线程要删除这个dom元素，此时浏览器就会一脸茫然，不知所措。所以，为了避免复杂性，从一诞生，JavaScript就是单线程，这已经成了这门语言的核心特征，将来也不会改变。

## 物理内存和虚拟内存

**物理内存：**物理内存（Physical memory）是相对于虚拟内存而言的。物理内存指通过物理内存条而获得的内存空间。
**虚拟内存：**相对于物理内存，在linux下还有一个虚拟内存的概念，虚拟内存就是为了满足物理内存的不足而提出的策略，它是利用磁盘空间虚拟出的一块逻辑内存，用作虚拟内存的磁盘空间被称为交换空间（Swap Space）

## 堆、栈

### 堆与栈区别

堆与栈实际上是操作系统对进程占用的内存空间的两种管理方式，主要有如下几种区别： 
（1）管理方式不同。栈由操作系统自动分配释放，无需我们手动控制；堆的申请和释放工作由程序员控制，容易产生内存泄漏； 
（2）空间大小不同。每个进程拥有的栈的大小要远远小于堆的大小。理论上，程序员可申请的堆大小为虚拟内存的大小，进程栈的大小64bits的Windows默认1M，64bits的Linux默认10M； 
（3）生长方向不同。堆的生长方向向上，内存地址由低到高；栈的生长方向向下，内存地址由高到低。 
（4）分配方式不同。堆都是动态分配的，没有静态分配的堆。栈有2种分配方式：静态分配和动态分配。静态分配是由操作系统完成的，比如局部变量的分配。动态分配由alloca函数进行分配，但是栈的动态分配和堆是不同的，他的动态分配是由操作系统进行释放，无需我们手工实现。 
（5）分配效率不同。栈由操作系统自动分配，会在硬件层级对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。堆则是由C/C++提供的库函数或运算符来完成申请与管理，实现机制较为复杂，频繁的内存申请容易产生内存碎片。显然，堆的效率比栈要低得多。 
（6）存放内容不同。栈存放的内容，函数返回地址、相关参数、局部变量和寄存器内容等。当主函数调用另外一个函数的时候，要对当前函数执行断点进行保存，需要使用栈来实现，首先入栈的是主函数下一条语句的地址，即扩展指针寄存器的内存（eip），然后是当前栈帧的底部地址，即扩展基址指针寄存器内容（ebp），再然后是被调函数的实参等，一般情况下是按照从右向左的顺序入栈，之后是调用函数的局部变量，注意静态变量是存放在数据段或者BSS段，是不入栈的。出栈的顺序正好相反，最终栈顶指向主函数下一条语句的地址，主程序又从该地址开始执行。堆，一般情况堆顶使用一个字节的空间来存放堆的大小，而堆中具体存放内容是由程序员来填充的。

从以上可以看到，堆和栈相比，由于大量malloc()/free()或new/delete的使用，容易造成大量的内存碎片，并且可能引发用户态和核心态的切换，效率较低。栈相比于堆，在程序中应用较为广泛，最常见的是函数的调用过程由栈来实现，函数返回地址、EBP、实参和局部变量都采用栈的方式存放。虽然栈有众多的好处，但是由于和堆相比不是那么灵活，有时候分配大量的内存空间，主要还是用堆。

无论是堆还是栈，在内存使用时都要防止非法越界，越界导致的非法内存访问可能会摧毁程序的堆、栈数据，轻则导致程序运行处于不确定状态，获取不到预期结果，重则导致程序异常崩溃，这些都是我们编程时与内存打交道时应该注意的问题。

### JS中的栈内存堆内存

JS的内存空间分为栈(stack)、堆(heap)、池(一般也会归类为栈中)。

其中栈存放变量，堆存放复杂对象，池存放常量，所以也叫常量池。

#### 栈数据结构

栈是一种特殊的列表，栈内的元素只能通过列表的一端访问，这一端称为栈顶。 栈被称为是一种后入先出（LIFO，last-in-first-out）的数据结构。 由于栈具有后入先出的特点，所以任何不在栈顶的元素都无法访问。 为了得到栈底的元素，必须先拿掉上面的元素。

在这里，为方便理解，通过类比乒乓球盒子来分析栈的存取方式。



![img](https://pic3.zhimg.com/80/v2-ea00180539b12493678e3cf99e8c1556_1440w.jpg)



这种乒乓球的存放方式与栈中存取数据的方式如出一辙。 处于盒子中最顶层的乒乓球 5，它一定是最后被放进去，但可以最先被使用。 而我们想要使用底层的乒乓球 1，就必须将上面的 4 个乒乓球取出来，让乒乓球1处于盒子顶层。 这就是栈空间先进后出，后进先出的特点。

#### 堆数据结构

堆是一种经过排序的树形数据结构，每个结点都有一个值。 通常我们所说的堆的数据结构，是指二叉堆。 堆的特点是根结点的值最小（或最大），且根结点的两个子树也是一个堆。 由于堆的这个特性，常用来实现优先队列，堆的存取是随意，这就如同我们在图书馆的书架上取书， 虽然书的摆放是有顺序的，但是我们想取任意一本时不必像栈一样，先取出前面所有的书， 我们只需要关心书的名字。

#### 变量类型与内存的关系

##### 基本数据类型

基本数据类型共有6种：

1. Sting
2. Number
3. Boolean
4. null
5. undefined
6. Symbol

基本数据类型保存在栈内存中，因为基本数据类型占用空间小、大小固定，通过按值来访问，属于被频繁使用的数据。

为了更好的搞懂基本数据类型变量与栈内存，我们结合以下例子与图解进行理解：

```text
let num1 = 1;
let num2 = 1;
```



![img](https://pic4.zhimg.com/80/v2-5509f2c90c578e95bf1f7f7e30a05143_1440w.jpg)



PS: 需要注意的是闭包中的基本数据类型变量不保存在栈内存中，而是保存在堆内存中。这个问题，我们后文再说。

##### 引用数据类型

Array,Function,Object...可以认为除了上文提到的基本数据类型以外，所有类型都是引用数据类型。

引用数据类型存储在堆内存中，因为引用数据类型占据空间大、大小不固定。 如果存储在栈中，将会影响程序运行的性能； 引用数据类型在栈中存储了指针，该指针指向堆中该实体的起始地址。 当解释器寻找引用值时，会首先检索其在栈中的地址，取得地址后从堆中获得实体

为了更好的搞懂变量对象与堆内存，我们结合以下例子与图解进行理解。

```text
// 基本数据类型-栈内存
let a1 = 0;
// 基本数据类型-栈内存
let a2 = 'this is string';
// 基本数据类型-栈内存
let a3 = null;
// 对象的指针存放在栈内存中，指针指向的对象存放在堆内存中
let b = { m: 20 };
// 数组的指针存放在栈内存中，指针指向的数组存放在堆内存中
let c = [1, 2, 3];
```



![img](https://pic4.zhimg.com/80/v2-c964a0c5d6a26b5561d67bd4ebd7d0bf_1440w.jpg)



因此当我们要访问堆内存中的引用数据类型时，实际上我们首先是从变量中获取了该对象的地址指针， 然后再从堆内存中取得我们需要的数据。

##### 从内存角度来看变量复制

##### 基本数据类型的复制

```text
let a = 20;
let b = a;
b = 30;
console.log(a); // 此时a的值是多少，是30？还是20？
复制代码
```

答案是：20

在这个例子中，a、b 都是基本类型，它们的值是存储在栈内存中的，a、b 分别有各自独立的栈空间， 所以修改了 b 的值以后，a 的值并不会发生变化。

从下图可以清晰的看到变量是如何复制并修改的。



![img](https://pic4.zhimg.com/80/v2-cb4832bfdba9f1a44052ec6262da0833_1440w.jpg)



##### 引用数据类型的复制

```text
let m = { a: 10, b: 20 };
let n = m;
n.a = 15;
console.log(m.a) //此时m.a的值是多少，是10？还是15？
```

答案是：15

在这个例子中，m、n都是引用类型，栈内存中存放地址指向堆内存中的对象， 引用类型的复制会为新的变量自动分配一个新的值保存在变量中， 但只是引用类型的一个地址指针而已，实际指向的是同一个对象， 所以修改 n.a 的值后，相应的 m.a 也就发生了改变。

从下图可以清晰的看到变量是如何复制并修改的。



![img](https://pic2.zhimg.com/80/v2-6bafc7df3c10ba76c4e6e1dd557c7a99_1440w.jpg)



#### 栈内存和堆内存的优缺点

在JS中，基本数据类型变量大小固定，并且操作简单容易，所以把它们放入栈中存储。 引用类型变量大小不固定，所以把它们分配给堆中，让他们申请空间的时候自己确定大小，这样把它们分开存储能够使得程序运行起来占用的内存最小。

栈内存由于它的特点，所以它的系统效率较高。 堆内存需要分配空间和地址，还要把地址存到栈中，所以效率低于栈。

#### 闭包与堆内存

闭包中的变量并不保存中栈内存中，而是保存在堆内存中。 这也就解释了函数调用之后之后为什么闭包还能引用到函数内的变量。

我们先来看什么是闭包：

```text
function A() {
 let a = 1;
 function B() {
 console.log(a);
 }
 return B;
}
let res = A();
```

函数 A 返回了一个函数 B，并且函数 B 中使用了函数 A 的变量，函数 B 就被称为闭包。

函数 A 弹出调用栈后，函数 A 中的变量这时候是存储在堆上的，所以函数B依旧能引用到函数A中的变量。 现在的 JS 引擎可以通过逃逸分析辨别出哪些变量需要存储在堆上，哪些需要存储在栈上。

#### 堆栈溢出

上边说道栈的数据会自动清除，而堆中的数据不会自动清除，需要手动清除。

每次存储数据，就会造成堆中的东西一直在增加，也就是当存储的数据达到某一限制时，就会造成堆栈溢出。

#### 内存泄漏

当不断的向堆中存储数据，而不进行清理，这就是内存泄漏。（内存泄漏的结果就是堆栈溢出）

#### 垃圾回收机制

为了不让内存泄漏，清理的方式就叫【垃圾回收机制】，（栈中不用的就自动清理，而堆不能）
一般分为两种：一种是自动清理，一种是手动清理(gc机制)。js中只有自动清理。清理的对象也可以叫做 ‘孤儿对象’ 。(堆中的数据的地址在栈中没有任何引用，这个堆中的数据对象就叫孤儿对象)

垃圾回收机制：就是将引用堆中地址的对象设置为null，并且将所有引用该地址的对象都设置为null,但是不会即时清除，因为垃圾回收车会根据内存的情况在适当的时候清除堆中的’孤儿对象’(也就是这个对象没有任何引用)

例如： 对上边的例子进行垃圾回收

设置 obj=null; 在栈中把obj的值设置为null，此时obj就没有引用堆中的数据对象，但是不会把堆中的数据对象清除掉，因为obj1还在引用它，所以堆中的数据对象，还不是"孤儿"，只有把obj1也设置为null，垃圾回收车才会在适当的时机把堆中的数据孤儿清理掉。

总结：如果想要清除复杂数据类型，也就是堆中的数据，必须将所有引用堆中地址的对象设置为null。

#### JS 垃圾回收算法

基本的垃圾回收算法称为**“标记-清除”**，定期执行以下“垃圾回收”步骤:

- 垃圾回收器获取根并**“标记”**(记住)它们。
- 然后它访问并“标记”所有来自它们的引用。
- 然后它访问标记的对象并标记它们的引用。所有被访问的对象都被记住，以便以后不再访问同一个对象两次。
- 以此类推，直到有未访问的引用(可以从根访问)为止。
- 除标记的对象外，所有对象都被删除。

例如，对象结构如下:

![图片描述](https://segmentfault.com/img/bVbqd7y)

我们可以清楚地看到右边有一个“不可到达的块”。现在让我们看看**“标记并清除”**垃圾回收器如何处理它。

**第一步标记根**

![图片描述](https://segmentfault.com/img/bVbqd7V)

**然后标记他们的引用**

![图片描述](https://segmentfault.com/img/bVbqd71)

以及子孙代的引用:

![图片描述](https://segmentfault.com/img/bVbqd8a)

现在进程中不能访问的对象被认为是不可访问的，将被删除:

![图片描述](https://segmentfault.com/img/bVbqd8A)

这就是垃圾收集的工作原理。JavaScript引擎应用了许多优化，使其运行得更快，并且不影响执行。

一些优化:

- **分代回收**——对象分为两组:“新对象”和“旧对象”。许多对象出现，完成它们的工作并迅速结 ，它们很快就会被清理干净。那些活得足够久的对象，会变“老”，并且很少接受检查。
- **增量回收**——如果有很多对象，并且我们试图一次遍历并标记整个对象集，那么可能会花费一些时间，并在执行中会有一定的延迟。因此，引擎试图将垃圾回收分解为多个部分。然后，各个部分分别执行。这需要额外的标记来跟踪变化，这样有很多微小的延迟，而不是很大的延迟。
- **空闲时间收集**——垃圾回收器只在 CPU 空闲时运行，以减少对执行的可能影响。